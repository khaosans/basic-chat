name: verifyExpected

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-xdist
      - name: Run unit tests only
        run: |
          pytest tests/ -m "unit or fast" -n auto --dist=worksteal -v --tb=short --cov=app --cov=reasoning_engine --cov=document_processor --cov=utils --cov=task_manager --cov=task_ui --cov=tasks --cov-report=term-missing
        env:
          # Task system configuration for testing
          ENABLE_BACKGROUND_TASKS: "true"
          REDIS_ENABLED: "false"
          CELERY_BROKER_URL: "redis://localhost:6379/0"
          MOCK_EXTERNAL_SERVICES: "true"
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: htmlcov/
          retention-days: 30

  integration-tests:
    runs-on: ubuntu-latest
    # Only run integration tests on main branch or when explicitly requested
    if: |
      github.ref == 'refs/heads/main' ||
      contains(github.event.head_commit.message, '[run-integration]') ||
      contains(github.event.pull_request.title, '[run-integration]')
    needs: unit-tests
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      - name: Setup test environment
        run: |
          # Create test data directory
          mkdir -p tests/data
          # Generate test files if they don't exist
          python scripts/generate_assets.py || echo "Test assets generation failed, continuing..."
      - name: Run integration tests
        run: |
          pytest tests/ -m "integration" -v --tb=short --timeout=300
        env:
          # Mock external services for integration tests
          MOCK_EXTERNAL_SERVICES: "true"
          CHROMA_PERSIST_DIR: "./test_chroma_db"
          # Task system configuration for integration testing
          ENABLE_BACKGROUND_TASKS: "true"
          REDIS_ENABLED: "false"
          CELERY_BROKER_URL: "redis://localhost:6379/0"
      - name: Cleanup test environment
        if: always()
        run: |
          # Clean up test files
          rm -rf ./test_chroma_db
          rm -rf temp_*.mp3
          rm -rf tests/data/test_*

  llm-judge:
    runs-on: ubuntu-latest
    # Run in parallel, don't wait for tests
    # Only run on pushes to main or trusted PRs (same repository)
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository)
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio openai
      - name: Run OpenAI LLM Judge Evaluator
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ vars.OPENAI_MODEL || 'gpt-3.5-turbo' }}
          LLM_JUDGE_THRESHOLD: ${{ vars.LLM_JUDGE_THRESHOLD || '7.0' }}
          # Task system configuration for LLM judge
          ENABLE_BACKGROUND_TASKS: "true"
          REDIS_ENABLED: "false"
          CELERY_BROKER_URL: "redis://localhost:6379/0"
        run: |
          if [ -z "$OPENAI_API_KEY" ]; then
            echo "‚ö†Ô∏è  No OpenAI API key found, skipping LLM Judge evaluation"
            exit 0
          fi
          
          echo "ü§ñ Running OpenAI LLM Judge evaluation with $OPENAI_MODEL..."
          python evaluators/check_llm_judge_openai.py --quick
      - name: Upload LLM Judge Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: llm-judge-results
          path: llm_judge_results.json
          retention-days: 30
